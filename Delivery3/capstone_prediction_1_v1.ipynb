{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "# Disable warnings, set Matplotlib inline plotting and load Pandas package\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "pd.set_option('display.width', 400)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "spark = SparkSession.builder.appName('Capstone Project V4').getOrCreate()\n",
    "orders= spark.read.csv(r\"D:\\TN\\Capstone\\Datasets\\orders.csv\", header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+--------+------------+---------+-----------------+----------------------+\n",
      "|order_id|user_id|eval_set|order_number|order_dow|order_hour_of_day|days_since_prior_order|\n",
      "+--------+-------+--------+------------+---------+-----------------+----------------------+\n",
      "| 2539329|      1|   prior|           1|        2|                8|                  null|\n",
      "| 2398795|      1|   prior|           2|        3|                7|                  15.0|\n",
      "|  473747|      1|   prior|           3|        3|               12|                  21.0|\n",
      "+--------+-------+--------+------------+---------+-----------------+----------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows     :  3421083\n",
      "Columns  :  7\n"
     ]
    }
   ],
   "source": [
    "print (\"Rows     : \" ,df.count())\n",
    "print (\"Columns  : \" ,len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+----------------------+\n",
      "|user_id|order_number|days_since_prior_order|\n",
      "+-------+------------+----------------------+\n",
      "|      1|           1|                  null|\n",
      "|      1|           2|                  15.0|\n",
      "|      1|           3|                  21.0|\n",
      "+-------+------------+----------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = ['user_id','order_number','days_since_prior_order']\n",
    "df_1 =df.select(*cols)\n",
    "df_1.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After dropping rows with null values\n",
      "                        0\n",
      "order_id                0\n",
      "user_id                 0\n",
      "eval_set                0\n",
      "order_number            0\n",
      "order_dow               0\n",
      "order_hour_of_day       0\n",
      "days_since_prior_order  0\n"
     ]
    }
   ],
   "source": [
    "#Data cleaning: removing days since prior order = 0.0 and removing first purchase as they have no days since prior order\n",
    "df = df.where(df[\"days_since_prior_order\"].isNotNull())\n",
    "df = df.where(df[\"days_since_prior_order\"]!=0)\n",
    "print(\"\")\n",
    "print(\"After dropping rows with null values\")\n",
    "print(df.select([F.count(F.when(F.isnan(c) | F.col(c).isNull(), c)).alias(c) for c in df.columns]).toPandas().transpose())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RFE Segmentation\\nRecency -> days since last purchase\\nFrequency -> Average time between each purchase\\nEngagement -> Visit Duration'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''RFE Segmentation\n",
    "Recency -> days since last purchase\n",
    "Frequency -> Average time between each purchase\n",
    "Engagement -> Visit Duration'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import rank, col\n",
    "\n",
    "\n",
    "window = Window.partitionBy(df_1['user_id']).orderBy(df_1['order_number'].desc())\n",
    "df_2=df_1.select('*', rank().over(window).alias('rank')) .filter(col('rank') <= 1).orderBy (df_1['user_id'])\n",
    "\n",
    "df_2 = df_2.withColumnRenamed('days_since_prior_order', 'recency')\n",
    "df_2 = df_2.withColumnRenamed('order_number', 'total_orders')\n",
    "df_2 = df_2.drop(\"order_number\",\"rank\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+-------+\n",
      "|user_id|total_orders|recency|\n",
      "+-------+------------+-------+\n",
      "|      1|          11|   14.0|\n",
      "+-------+------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_2.where(df['user_id']==1).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "df_4=df_1.withColumn(\"frequency\", F.avg('days_since_prior_order').over(window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+\n",
      "|user_id|Visit_duration|\n",
      "+-------+--------------+\n",
      "|      1|         190.0|\n",
      "|      2|         228.0|\n",
      "|      3|         144.0|\n",
      "|      4|          85.0|\n",
      "|      5|          46.0|\n",
      "+-------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "df_3=df_1.groupBy('user_id').agg(sum('days_since_prior_order').alias('Visit_duration')).orderBy(df_1['user_id'])\n",
    "df_3.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_2.join(df_3, on=['user_id'],how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+-------+--------------+\n",
      "|user_id|total_orders|recency|Visit_duration|\n",
      "+-------+------------+-------+--------------+\n",
      "|      1|          11|   14.0|         190.0|\n",
      "+-------+------------+-------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df['user_id']==1).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "window1 = Window.partitionBy(df_1['user_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_5=df_1.select('*', F.avg('days_since_prior_order').over(window1).alias('Frequency')).orderBy(df['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#last 10 visits frequency average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4=df_1.select('*', rank().over(window).alias('rank')) .filter(col('rank') <= 10).orderBy (df_1['user_id'])\n",
    "df_4 = df_4.drop(\"order_number\",\"rank\")\n",
    "df_4=df_4.withColumn('frequency', F.round(F.avg('days_since_prior_order').over(window1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------+---------+\n",
      "|user_id|days_since_prior_order|frequency|\n",
      "+-------+----------------------+---------+\n",
      "|      1|                  15.0|     19.0|\n",
      "|      1|                  21.0|     19.0|\n",
      "|      1|                  29.0|     19.0|\n",
      "|      1|                  28.0|     19.0|\n",
      "|      1|                  19.0|     19.0|\n",
      "|      1|                  20.0|     19.0|\n",
      "|      1|                  14.0|     19.0|\n",
      "|      1|                   0.0|     19.0|\n",
      "|      1|                  30.0|     19.0|\n",
      "|      1|                  14.0|     19.0|\n",
      "|      2|                  13.0|     20.0|\n",
      "|      2|                  14.0|     20.0|\n",
      "|      2|                  27.0|     20.0|\n",
      "|      2|                   8.0|     20.0|\n",
      "|      2|                   6.0|     20.0|\n",
      "|      2|                  30.0|     20.0|\n",
      "|      2|                  28.0|     20.0|\n",
      "|      2|                  30.0|     20.0|\n",
      "|      2|                  13.0|     20.0|\n",
      "|      2|                  30.0|     20.0|\n",
      "+-------+----------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = ['user_id','order_number']\n",
    "df_4.orderBy(*cols, ascending = True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = df_4.drop(\"days_since_prior_order\").dropDuplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_4.join(df, on = 'user_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------------+-------+--------------+\n",
      "|user_id|frequency|total_orders|recency|Visit_duration|\n",
      "+-------+---------+------------+-------+--------------+\n",
      "|      1|     19.0|          11|   14.0|         190.0|\n",
      "+-------+---------+------------+-------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df[\"user_id\"]==1).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import avg\n",
    "freq=df_1.groupBy('user_id').(avg('days_since_prior_order').alias('Frequency')).orderBy(df_1['user_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "df_e=df_1.select('*', ('days_since_prior_order').over(window1).alias('Visit_duration'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  summary            user_id           frequency        total_orders             recency      Visit_duration\n",
      "0   count             206209              206209              206209              206209              206209\n",
      "1    mean           103105.0  15.568432997589824  16.590367054784224  17.061781978478145   173.2843765306073\n",
      "2  stddev  59527.55516705405   7.030657928294545  16.654773501154427  10.672178387505193  100.99896693408382\n",
      "3     min                  1                 0.0                   4                 0.0                 0.0\n",
      "4     max             206209                30.0                 100                30.0               365.0\n"
     ]
    }
   ],
   "source": [
    "print(df.describe().toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r_quartile = df.approxQuantile(\"Recency\", [0.25, 0.5, 0.75], 0)\n",
    "f_quartile = df.approxQuantile(\"Frequency\", [0.25, 0.5, 0.75], 0)\n",
    "v_quartile = df.approxQuantile(\"Visit_duration\", [0.25, 0.5, 0.75], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when,concat\n",
    "df = df.withColumn(\"r_quartile\", when(col(\"Recency\") >= r_quartile[2] , 1).when(col(\"Recency\") >= r_quartile[1] , 2).when(col(\"Recency\") >= r_quartile[0] , 3).otherwise(4))\n",
    "df = df.withColumn(\"f_quartile\", when(col(\"Frequency\") >= r_quartile[2] , 1).when(col(\"Frequency\") >= r_quartile[1] , 2).when(col(\"Frequency\") >= r_quartile[0] , 3).otherwise(4))\n",
    "df = df.withColumn(\"e_quartile\", when(col(\"Visit_duration\") >= r_quartile[2] , 1).when(col(\"Visit_duration\") >= r_quartile[1] , 2).when(col(\"Visit_duration\") >= r_quartile[0] , 3).otherwise(4))\n",
    "\n",
    "\n",
    "df = df.withColumn(\"RFE_Score\", concat(col(\"r_quartile\"), col(\"f_quartile\"), col(\"e_quartile\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('user_id', 'int'),\n",
       " ('frequency', 'double'),\n",
       " ('total_orders', 'int'),\n",
       " ('recency', 'double'),\n",
       " ('Visit_duration', 'double'),\n",
       " ('r_quartile', 'int'),\n",
       " ('f_quartile', 'int'),\n",
       " ('e_quartile', 'int'),\n",
       " ('RFE_Score', 'string')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------------+-------+--------------+----------+----------+----------+---------+\n",
      "|user_id|frequency|total_orders|recency|Visit_duration|r_quartile|f_quartile|e_quartile|RFE_Score|\n",
      "+-------+---------+------------+-------+--------------+----------+----------+----------+---------+\n",
      "|    148|     10.0|           8|   27.0|          69.0|         2|         3|         1|      231|\n",
      "|    463|     19.0|           8|   25.0|         133.0|         2|         2|         1|      221|\n",
      "|    471|     11.0|           7|   10.0|          65.0|         3|         3|         1|      331|\n",
      "|    496|      2.0|          83|    2.0|         280.0|         4|         4|         1|      441|\n",
      "|    833|     20.0|          12|   22.0|         233.0|         2|         2|         1|      221|\n",
      "+-------+---------+------------+-------+--------------+----------+----------+----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('user_id', 'int'),\n",
       " ('frequency', 'double'),\n",
       " ('total_orders', 'int'),\n",
       " ('recency', 'double'),\n",
       " ('Visit_duration', 'double'),\n",
       " ('r_quartile', 'int'),\n",
       " ('f_quartile', 'int'),\n",
       " ('e_quartile', 'int'),\n",
       " ('RFE_Score', 'string')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting label recency to categorical column\n",
    "def purchase_interval(r):\n",
    "    if r <= 10:\n",
    "        return \"Class0\"\n",
    "    elif (r > 10) & (r <= 20):\n",
    "        return \"Class1\"\n",
    "    elif (r > 20) & (r <= 30):\n",
    "        return \"Class2\"\n",
    "    elif r > 30:\n",
    "        return \"Class3\"\n",
    "\n",
    "ol_val = udf(purchase_interval, StringType())\n",
    "\n",
    "df = df.withColumn(\"purchase_interval\",F.lit(ol_val(df.recency)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target column is  Column<b'purchase_interval'>\n"
     ]
    }
   ],
   "source": [
    "#target column identification\n",
    "target_col = df[\"purchase_interval\"]\n",
    "print(\"Target column is \",target_col)\n",
    "drptar = df.drop(\"purchase_interval\",\"recency\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical columns:  ['user_id', 'frequency', 'total_orders', 'Visit_duration', 'r_quartile', 'f_quartile', 'e_quartile']\n",
      "categorical columns:  ['RFE_Score']\n"
     ]
    }
   ],
   "source": [
    "num_cols = [t[0] for t in drptar.dtypes if t[1] == 'int' or t[1] == 'double']\n",
    "#num_cols = df._get_numeric_data().columns\n",
    "print(\"numerical columns: \",num_cols)\n",
    "cat_cols = [t[0] for t in drptar.dtypes if t[1] == 'string']\n",
    "print(\"categorical columns: \",cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing using StringIndexer, OneHotEncoder and VectorAssembler. First the input categorical columns are indexed using stringIndexer and then converted to corresponding numeric category using OneHotEncoderEstimator and assembled into a vector dataframe format using Vector Assembler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "categoricalColumns = cat_cols\n",
    "stages = []\n",
    "for categoricalCol in categoricalColumns:\n",
    "    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n",
    "    encoder = OneHotEncoderEstimator(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "    stages += [stringIndexer, encoder]\n",
    "    \n",
    "label_stringIdx = StringIndexer(inputCol = 'purchase_interval', outputCol = 'label')\n",
    "stages += [label_stringIdx]\n",
    "#numericCols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "numericCols = num_cols\n",
    "assemblerInputs = [a + \"classVec\" for a in categoricalColumns] + numericCols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- frequency: double (nullable = true)\n",
      " |-- total_orders: integer (nullable = true)\n",
      " |-- recency: double (nullable = true)\n",
      " |-- Visit_duration: double (nullable = true)\n",
      " |-- r_quartile: integer (nullable = false)\n",
      " |-- f_quartile: integer (nullable = false)\n",
      " |-- e_quartile: integer (nullable = false)\n",
      " |-- RFE_Score: string (nullable = false)\n",
      " |-- purchase_interval: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = df.columns\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages = stages)\n",
    "pipelineModel = pipeline.fit(df)\n",
    "df = pipelineModel.transform(df)\n",
    "selectedCols = ['label', 'features'] + columns\n",
    "df = df.select(selectedCols)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df.randomSplit([0.8, 0.2], seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.5771401364717283\n",
      "Test Accuracy: 0.5734632092520514\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "nbModel = nb.fit(train)\n",
    "Train_predictions = nbModel.transform(train)\n",
    "predictions = nbModel.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)\n",
    "print('Training accuracy: ' + str(evaluator.evaluate(Train_predictions)))\n",
    "print(\"Test Accuracy: \" + str(evaluator.evaluate(predictions)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_pandas = predictions.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12449  3270  1625]\n",
      " [ 4726  9313  1525]\n",
      " [ 3381  2733  2518]]\n"
     ]
    }
   ],
   "source": [
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(predictions_pandas.label, predictions_pandas.prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0     0.6056    0.7178    0.6569     17344\n",
      "        1.0     0.6081    0.5984    0.6032     15564\n",
      "        2.0     0.4442    0.2917    0.3522      8632\n",
      "\n",
      "avg / total     0.5730    0.5845    0.5735     41540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the precision and recall for each label\n",
    "print(metrics.classification_report(predictions_pandas.label, predictions_pandas.prediction, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.7145423990192628\n",
      "Test Accuracy: 0.7099387904215853\n",
      "[[17281     0    63]\n",
      " [    0 15564     0]\n",
      " [ 3998  4452   182]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0     0.8121    0.9964    0.8949     17344\n",
      "        1.0     0.7776    1.0000    0.8749     15564\n",
      "        2.0     0.7429    0.0211    0.0410      8632\n",
      "\n",
      "avg / total     0.7848    0.7951    0.7099     41540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\",featuresCol=\"features\",numTrees = 10,maxBins = 32)\n",
    "# Train model with Training Data\n",
    "RFmodel = rf.fit(train)\n",
    "predictions = RFmodel.transform(test)\n",
    "Train_predictions = RFmodel.transform(train)\n",
    "evaluator = MulticlassClassificationEvaluator()\n",
    "print('Training accuracy: ' + str(evaluator.evaluate(Train_predictions)))\n",
    "print(\"Test Accuracy: \" + str(evaluator.evaluate(predictions)))\n",
    "predictions_pandas = predictions.toPandas()\n",
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(predictions_pandas.label, predictions_pandas.prediction))\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(predictions_pandas.label, predictions_pandas.prediction, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.7998183688399056\n",
      "Test Accuracy: 0.7972353490206296\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(maxIter=40)\n",
    "lrModel = lr.fit(train)\n",
    "Train_predictions = lrModel.transform(train)\n",
    "predictions = lrModel.transform(test)\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)\n",
    "print('Training accuracy: ' + str(evaluator.evaluate(Train_predictions)))\n",
    "print(\"Test Accuracy: \" + str(evaluator.evaluate(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[61972     0  6530]\n",
      " [    0 58681  3798]\n",
      " [ 7547 12967 13174]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0     0.8914    0.9047    0.8980     68502\n",
      "        1.0     0.8190    0.9392    0.8750     62479\n",
      "        2.0     0.5605    0.3911    0.4607     33688\n",
      "\n",
      "avg / total     0.7963    0.8127    0.7998    164669\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Train_predictions_pandas = Train_predictions.toPandas()\n",
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(Train_predictions_pandas.label, Train_predictions_pandas.prediction))\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(Train_predictions_pandas.label, Train_predictions_pandas.prediction, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15639     0  1705]\n",
      " [    0 14626   938]\n",
      " [ 1933  3310  3389]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0     0.8900    0.9017    0.8958     17344\n",
      "        1.0     0.8155    0.9397    0.8732     15564\n",
      "        2.0     0.5618    0.3926    0.4622      8632\n",
      "\n",
      "avg / total     0.7939    0.8102    0.7972     41540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_pandas = predictions.toPandas()\n",
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(predictions_pandas.label, predictions_pandas.prediction))\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(predictions_pandas.label, predictions_pandas.prediction, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class0:  68502\n",
      "class1:  62479\n",
      "class2:  33688\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"class0: \",train.filter(train['label']==0).count())\n",
    "print(\"class1: \",train.filter(train['label']==1).count())\n",
    "print(\"class2: \",train.filter(train['label']==2).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an imbalance in dataset\n",
    "So, in case of logistic regression, i hope adding classweights in weightcol parameter would increase class2 prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BalancingRatio= numNegatives/dataset_size\n",
    "#print('BalancingRatio: '+ str(BalancingRatio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HyperParameter Tuning\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "paramGrid = ParamGridBuilder().addGrid(lr.aggregationDepth,[2,5,10]).addGrid(lr.elasticNetParam,[0.0, 0.5, 1.0]).addGrid(lr.fitIntercept,[False, True]).addGrid(lr.maxIter,[10, 100, 1000]).addGrid(lr.regParam,[0.01, 0.5, 2.0]).build()\n",
    "# Creating 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "# fitting the model\n",
    "cvModel = cv.fit(train)\n",
    "Train_predictions=cvModel.transform(train)\n",
    "predictions=cvModel.transform(test)\n",
    "print('Training accuracy: ' + str(evaluator.evaluate(Train_predictions)))\n",
    "print(\"Test Accuracy: \" + str(evaluator.evaluate(predictions)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
